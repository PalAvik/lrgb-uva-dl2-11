Graph neural networks (GNNs) have emerged as a powerful model for analyzing graph-structured data in various domains, including molecular biology and computer vision. In molecular biology, GNNs have shown promising results in predicting the properties of chemical compounds, such as solubility, toxicity, and bioactivity, by representing molecules as graphs and processing the structural and chemical features of the compounds. In computer vision, GNNs have been applied to tasks such as image captioning, where the goal is to generate a natural language description of an image. In this context, graphs can be used to represent the relationships between the objects and regions in the image, enabling GNNs to capture the spatial and semantic dependencies of the visual content.

GNNs can have difficulty capturing relationships between nodes that are far apart in the graph, which can limit their performance on tasks that involve long-range dependencies. This is because traditional GNN architectures typically operate on a fixed-size neighborhood around each node, which may not capture the full range of interactions necessary for accurate predictions. This problem is especially severe in graphs with a lot of bottlenecks - points where the graph is significantly narrower and the distance between nodes is increased.

[paper] attempted to form a benchmark for testing GNNs against this class of problems, consisting of molecular and image captioning datasets. However, the authors have not attempted to evaluate the amount and size of long-range interaction problems in the graphs of their benchmarks. This requires the discovery of useful metrics for evaluating the level of bottleneck and the length of interactions the graph requires, as well as examining whether models do actually require to use long range information in the graphs to create useful predictions.

In this paper we analyse the usage of the cheeger constant and minimal average path as measurements of LRI in the graph by attempting to find a correlation between the values of these metrics and the level of influence of long-range interactions on different models' prediction.

Cheeger constant is a measure of the connectivity and compactness of a graph, which is often used in spectral graph theory and geometric graph theory. It measures the minimum ratio between the cut size and the volume of a set of vertices, over all possible sets of vertices. The cut size is the number of edges that cross the boundary between the set of vertices and its complement, while the volume is the total number of vertices in the set. Intuitively, a graph with a small Cheeger constant has a "narrow waist" that separates two densely connected regions, while a graph with a large Cheeger constant has a more uniform distribution of edges and vertices. The Cheeger constant is often used as a measure of the degree of bottleneck or bottleneck-free-ness of a graph, which can affect the performance of GNNs that operate on the graph.

The minimal average path is another metric that is commonly used to measure the distance between nodes in a graph. It is defined as the minimum average path length between all pairs of nodes in the graph. The average path length between two nodes is the average number of edges that need to be traversed to go from one node to the other, over all possible pairs of nodes. The minimal average path is often used as a measure of the overall connectivity and sparsity of a graph, which can affect the ability of GNNs to capture long-range dependencies and relationships between distant nodes.
