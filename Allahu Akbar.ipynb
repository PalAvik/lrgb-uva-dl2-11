{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15820996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting e3nn\n",
      "  Downloading e3nn-0.5.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m367.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from e3nn) (1.12.1)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/opt-einsum-fx/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opt-einsum-fx>=0.1.4\n",
      "  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: scipy in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from e3nn) (1.10.0)\n",
      "Requirement already satisfied: opt-einsum in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from opt-einsum-fx>=0.1.4->e3nn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from opt-einsum-fx>=0.1.4->e3nn) (21.3)\n",
      "Requirement already satisfied: typing_extensions in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from torch>=1.8.0->e3nn) (4.4.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from scipy->e3nn) (1.23.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages (from packaging->opt-einsum-fx>=0.1.4->e3nn) (3.0.9)\n",
      "Installing collected packages: mpmath, sympy, opt-einsum-fx, e3nn\n",
      "Successfully installed e3nn-0.5.1 mpmath-1.3.0 opt-einsum-fx-0.1.4 sympy-1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade e3nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f12ae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/toqulkdpb1jrswk/voc_superpixels_edge_wt_only_coord.zip?dl=1\n",
      "Extracting ./voc_superpixels_edge_wt_only_coord.zip\n",
      "Processing...\n",
      "Processing train dataset: 100%|███████████| 8498/8498 [00:02<00:00, 3801.09it/s]\n",
      "Processing val dataset: 100%|█████████████| 1428/1428 [00:00<00:00, 6142.10it/s]\n",
      "Processing test dataset: 100%|███████████| 1429/1429 [00:00<00:00, 12234.23it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_zip)\n",
    "\n",
    "\n",
    "class VOCSuperpixels(InMemoryDataset):\n",
    "    r\"\"\"The VOCSuperpixels dataset which contains image superpixels and a semantic segmentation label\n",
    "    for each node superpixel.\n",
    "    \n",
    "    Construction and Preparation:\n",
    "    - The superpixels are extracted in a similar fashion as the MNIST and CIFAR10 superpixels. \n",
    "    - In VOCSuperpixels, the number of superpixel nodes <=500. (Note that it was <=75 for MNIST and\n",
    "    <=150 for CIFAR10.)\n",
    "    - The labeling of each superpixel node is done with the same value of the original pixel ground\n",
    "    truth  that is on the mean coord of the superpixel node\n",
    "    \n",
    "    - Based on the SBD annotations from 11355 images taken from the PASCAL VOC 2011 dataset. Original\n",
    "    source `here<https://github.com/shelhamer/fcn.berkeleyvision.org/tree/master/data/pascal>`_.\n",
    "    \n",
    "    num_classes = 21\n",
    "    ignore_label = 255\n",
    "\n",
    "    color map\n",
    "    0=background, 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle, 6=bus, 7=car, 8=cat, 9=chair, 10=cow,\n",
    "    11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person, 16=potted plant, 17=sheep, 18=sofa, 19=train,\n",
    "    20=tv/monitor\n",
    "    \n",
    "    Splitting:\n",
    "    - In the original image dataset there are only train and val splitting.\n",
    "    - For VOCSuperpixels, we maintain train, val and test splits where the train set is AS IS. The original\n",
    "    val split of the image dataset is used to divide into new val and new test split that is eventually used\n",
    "    in VOCSuperpixels. The policy for this val/test splitting is below.\n",
    "    - Split total number of val graphs into 2 sets (val, test) with 50:50 using a stratified split proportionate\n",
    "    to original distribution of data with respect to a meta label.\n",
    "    - Each image is meta-labeled by majority voting of non-background grouth truth node labels. Then new val\n",
    "    and new test is created with stratified sampling based on these meta-labels. This is done for preserving\n",
    "    same distribution of node labels in both new val and new test\n",
    "    - Therefore, the final train, val and test splits are correspondingly original train (8498), new val (1428)\n",
    "    and new test (1429) splits.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        name (string, optional): Option to select the graph construction format.\n",
    "            If :obj: `\"edge_wt_only_coord\"`, the graphs are 8-nn graphs with the edge weights computed based on\n",
    "            only spatial coordinates of superpixel nodes.\n",
    "            If :obj: `\"edge_wt_coord_feat\"`, the graphs are 8-nn graphs with the edge weights computed based on\n",
    "            combination of spatial coordinates and feature values of superpixel nodes.\n",
    "            If :obj: `\"edge_wt_region_boundary\"`, the graphs region boundary graphs where two regions (i.e. \n",
    "            superpixel nodes) have an edge between them if they share a boundary in the original image.\n",
    "            (default: :obj:`\"edge_wt_region_boundary\"`)\n",
    "        slic_compactness (int, optional): Option to select compactness of slic that was used for superpixels\n",
    "            (:obj:`10`, :obj:`30`). (default: :obj:`30`)\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "        pre_filter (callable, optional): A function that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "            value, indicating whether the data object should be included in the\n",
    "            final dataset. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    \n",
    "    url = {\n",
    "        10: {\n",
    "        'edge_wt_only_coord': 'https://www.dropbox.com/s/rk6pfnuh7tq3t37/voc_superpixels_edge_wt_only_coord.zip?dl=1',\n",
    "        'edge_wt_coord_feat': 'https://www.dropbox.com/s/2a53nmfp6llqg8y/voc_superpixels_edge_wt_coord_feat.zip?dl=1',\n",
    "        'edge_wt_region_boundary': 'https://www.dropbox.com/s/6pfz2mccfbkj7r3/voc_superpixels_edge_wt_region_boundary.zip?dl=1'\n",
    "        },\n",
    "        30: {\n",
    "        'edge_wt_only_coord': 'https://www.dropbox.com/s/toqulkdpb1jrswk/voc_superpixels_edge_wt_only_coord.zip?dl=1',\n",
    "        'edge_wt_coord_feat': 'https://www.dropbox.com/s/xywki8ysj63584d/voc_superpixels_edge_wt_coord_feat.zip?dl=1',\n",
    "        'edge_wt_region_boundary': 'https://www.dropbox.com/s/8x722ai272wqwl4/voc_superpixels_edge_wt_region_boundary.zip?dl=1'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, root, name='edge_wt_region_boundary', slic_compactness=30, split='train',\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.name = name\n",
    "        self.slic_compactness = slic_compactness\n",
    "        assert split in ['train', 'val', 'test']\n",
    "        assert name in ['edge_wt_only_coord', 'edge_wt_coord_feat', 'edge_wt_region_boundary']\n",
    "        assert slic_compactness in [10, 30]\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        path = osp.join(self.processed_dir, f'{split}.pt')\n",
    "        self.data, self.slices = torch.load(path)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.pickle', 'val.pickle', 'test.pickle']\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return osp.join(self.root,\n",
    "                        'slic_compactness_' + str(self.slic_compactness),\n",
    "                        self.name,\n",
    "                        'raw')\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return osp.join(self.root,\n",
    "                        'slic_compactness_' + str(self.slic_compactness),\n",
    "                        self.name,\n",
    "                        'processed')\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train.pt', 'val.pt', 'test.pt']\n",
    "\n",
    "    def download(self):\n",
    "        shutil.rmtree(self.raw_dir)\n",
    "        path = download_url(self.url[self.slic_compactness][self.name], self.root)\n",
    "        extract_zip(path, self.root)\n",
    "        os.rename(osp.join(self.root, 'voc_superpixels_' + self.name), self.raw_dir)\n",
    "        os.unlink(path)\n",
    "    \n",
    "    def process(self):\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            with open(osp.join(self.raw_dir, f'{split}.pickle'), 'rb') as f:\n",
    "                graphs = pickle.load(f)\n",
    "\n",
    "            indices = range(len(graphs))\n",
    "\n",
    "            pbar = tqdm(total=len(indices))\n",
    "            pbar.set_description(f'Processing {split} dataset')\n",
    "\n",
    "            data_list = []\n",
    "            for idx in indices:\n",
    "                graph = graphs[idx] \n",
    "                \n",
    "                \"\"\"\n",
    "                Each `graph` is a tuple (x, edge_attr, edge_index, y)\n",
    "                    Shape of x : [num_nodes, 14]\n",
    "                    Shape of edge_attr : [num_edges, 1] or [num_edges, 2]\n",
    "                    Shape of edge_index : [2, num_edges]\n",
    "                    Shape of y : [num_nodes]\n",
    "                \"\"\"\n",
    "                \n",
    "                x = graph[0].to(torch.float)\n",
    "                edge_attr = graph[1].to(torch.float)\n",
    "                edge_index = graph[2]\n",
    "                y = torch.LongTensor(graph[3])\n",
    "\n",
    "                data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                            y=y)\n",
    "\n",
    "                if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                    continue\n",
    "\n",
    "                if self.pre_transform is not None:\n",
    "                    data = self.pre_transform(data)\n",
    "\n",
    "                data_list.append(data)\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            torch.save(self.collate(data_list),\n",
    "                       osp.join(self.processed_dir, f'{split}.pt'))\n",
    "\n",
    "            \n",
    "def join_dataset_splits(datasets):\n",
    "    \"\"\"Join train, val, test datasets into one dataset object.\n",
    "\n",
    "    Args:\n",
    "        datasets: list of 3 PyG datasets to merge\n",
    "\n",
    "    Returns:\n",
    "        joint dataset with `split_idxs` property storing the split indices\n",
    "    \"\"\"\n",
    "    assert len(datasets) == 3, \"Expecting train, val, test datasets\"\n",
    "\n",
    "    n1, n2, n3 = len(datasets[0]), len(datasets[1]), len(datasets[2])\n",
    "    data_list = [datasets[0].get(i) for i in range(n1)] + \\\n",
    "                [datasets[1].get(i) for i in range(n2)] + \\\n",
    "                [datasets[2].get(i) for i in range(n3)]\n",
    "\n",
    "    datasets[0]._indices = None\n",
    "    datasets[0]._data_list = data_list\n",
    "    datasets[0].data, datasets[0].slices = datasets[0].collate(data_list)\n",
    "    split_idxs = [list(range(n1)),\n",
    "                  list(range(n1, n1 + n2)),\n",
    "                  list(range(n1 + n2, n1 + n2 + n3))]\n",
    "    datasets[0].split_idxs = split_idxs\n",
    "\n",
    "    return datasets[0]            \n",
    "            \n",
    "            \n",
    "    \n",
    "def preformat_VOCSuperpixels(dataset_dir, name, slic_compactness):\n",
    "    \"\"\"Load and preformat VOCSuperpixels dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir: path where to store the cached dataset\n",
    "    Returns:\n",
    "        PyG dataset object\n",
    "    \"\"\"\n",
    "    dataset = join_dataset_splits(\n",
    "        [VOCSuperpixels(root=dataset_dir, name=name,\n",
    "                        slic_compactness=slic_compactness,\n",
    "                        split=split)\n",
    "         for split in ['train', 'val', 'test']]\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "dataset_dir=''\n",
    "name='edge_wt_only_coord'\n",
    "dataset = preformat_VOCSuperpixels(dataset_dir, name, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdeb3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[460, 14], edge_index=[2, 3680], edge_attr=[3680, 1], y=[460])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27155fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import Irreps\n",
    "from e3nn.o3 import Linear, spherical_harmonics, FullyConnectedTensorProduct\n",
    "\n",
    "\n",
    "def BalancedIrreps(lmax, vec_dim, sh_type=True):\n",
    "    \"\"\" Allocates irreps equally along channel budget, resulting\n",
    "        in unequal numbers of irreps in ratios of 2l_i + 1 to 2l_j + 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lmax : int\n",
    "        Maximum order of irreps.\n",
    "    vec_dim : int\n",
    "        Dim of feature vector.\n",
    "    sh_type : bool\n",
    "        if true, use spherical harmonics. Else the full set of irreps (with redundance).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Irreps\n",
    "        Resulting irreps for feature vectors.\n",
    "\n",
    "    \"\"\"\n",
    "    irrep_spec = \"0e\"\n",
    "    for l in range(1, lmax + 1):\n",
    "        if sh_type:\n",
    "            irrep_spec += \" + {0}\".format(l) + ('e' if (l % 2) == 0 else 'o')\n",
    "        else:\n",
    "            irrep_spec += \" + {0}e + {0}o\".format(l)\n",
    "    irrep_spec_split = irrep_spec.split(\" + \")\n",
    "    dims = [int(irrep[0]) * 2 + 1 for irrep in irrep_spec_split]\n",
    "    # Compute ratios\n",
    "    ratios = [1 / dim for dim in dims]\n",
    "    # Determine how many copies per irrep\n",
    "    irrep_copies = [int(vec_dim * r / len(ratios)) for r in ratios]\n",
    "    # Determine the current effective irrep sizes\n",
    "    irrep_dims = [n * dim for (n, dim) in zip(irrep_copies, dims)]\n",
    "    # Add trivial irreps until the desired size is reached\n",
    "    irrep_copies[0] += vec_dim - sum(irrep_dims)\n",
    "\n",
    "    # Convert to string\n",
    "    str_out = ''\n",
    "    for (spec, dim) in zip(irrep_spec_split, irrep_copies):\n",
    "        str_out += str(dim) + 'x' + spec\n",
    "        str_out += ' + '\n",
    "    str_out = str_out[:-3]\n",
    "    # Generate the irrep\n",
    "    return Irreps(str_out)\n",
    "\n",
    "\n",
    "def WeightBalancedIrreps(irreps_in1_scalar, irreps_in2, sh=True, lmax=None):\n",
    "    \"\"\"Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product\n",
    "    irreps_in1 x irreps_in2 -> irreps_in1\n",
    "    would have the same number of weights as for a standard linear layer, e.g. a tensor product\n",
    "    irreps_in1_scalar x \"1x0e\" -> irreps_in1_scalar\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in1_scalar : o3.Irreps\n",
    "        Number of hidden features, represented by zeroth order irreps.\n",
    "    irreps_in2 : o3.Irreps\n",
    "        Irreps related to edge attributes.\n",
    "    sh : bool\n",
    "        if true, yields equal number of every order. Else returns balanced irrep.\n",
    "    lmax : int\n",
    "        Maximum order irreps to be considered.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    o3.Irreps\n",
    "        Irreps for hidden feaure vectors.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n = 1\n",
    "    if lmax == None:\n",
    "        lmax = irreps_in2.lmax\n",
    "    irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)\n",
    "    weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel\n",
    "    weight_numel_scalar = FullyConnectedTensorProduct(irreps_in1_scalar, Irreps(\"1x0e\"), irreps_in1_scalar).weight_numel\n",
    "    while weight_numel1 < weight_numel_scalar:  # TODO: somewhat suboptimal implementation...\n",
    "        n += 1\n",
    "        irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)\n",
    "        weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel\n",
    "    print('Determined irrep type:', irreps_in1)\n",
    "    return Irreps(irreps_in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea33b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "from e3nn.o3 import Irreps\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class InstanceNorm(nn.Module):\n",
    "    '''Instance normalization for orthonormal representations\n",
    "    It normalizes by the norm of the representations.\n",
    "    Note that the norm is invariant only for orthonormal representations.\n",
    "    Irreducible representations `wigner_D` are orthonormal.\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps : `Irreps`\n",
    "        representation\n",
    "    eps : float\n",
    "        avoid division by zero when we normalize by the variance\n",
    "    affine : bool\n",
    "        do we have weight and bias parameters\n",
    "    reduce : {'mean', 'max'}\n",
    "        method used to reduce\n",
    "    '''\n",
    "\n",
    "    def __init__(self, irreps, eps=1e-5, affine=True, reduce='mean', normalization='component'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.irreps = Irreps(irreps)\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        num_scalar = sum(mul for mul, ir in self.irreps if ir.l == 0)\n",
    "        num_features = self.irreps.num_irreps\n",
    "\n",
    "        if affine:\n",
    "            self.weight = nn.Parameter(torch.ones(num_features))\n",
    "            self.bias = nn.Parameter(torch.zeros(num_scalar))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        assert isinstance(reduce, str), \"reduce should be passed as a string value\"\n",
    "        assert reduce in ['mean', 'max'], \"reduce needs to be 'mean' or 'max'\"\n",
    "        self.reduce = reduce\n",
    "\n",
    "        assert normalization in ['norm', 'component'], \"normalization needs to be 'norm' or 'component'\"\n",
    "        self.normalization = normalization\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__} ({self.irreps}, eps={self.eps})\"\n",
    "\n",
    "    def forward(self, input, batch):\n",
    "        '''evaluate\n",
    "        Parameters\n",
    "        ----------\n",
    "        input : `torch.Tensor`\n",
    "            tensor of shape ``(batch, ..., irreps.dim)``\n",
    "        Returns\n",
    "        -------\n",
    "        `torch.Tensor`\n",
    "            tensor of shape ``(batch, ..., irreps.dim)``\n",
    "        '''\n",
    "        # batch, *size, dim = input.shape  # TODO: deal with batch\n",
    "        # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]\n",
    "        # input has shape [batch * nodes, dim], but with variable nr of nodes.\n",
    "        # the input batch slices this into separate graphs\n",
    "        dim = input.shape[-1]\n",
    "\n",
    "        fields = []\n",
    "        ix = 0\n",
    "        iw = 0\n",
    "        ib = 0\n",
    "\n",
    "        for mul, ir in self.irreps:  # mul is the multiplicity (number of copies) of some irrep type (ir)\n",
    "            d = ir.dim\n",
    "            field = input[:, ix: ix + mul * d]  # [batch * sample, mul * repr]\n",
    "            ix += mul * d\n",
    "\n",
    "            # [batch * sample, mul, repr]\n",
    "            field = field.reshape(-1, mul, d)\n",
    "\n",
    "            # For scalars first compute and subtract the mean\n",
    "            if ir.l == 0:\n",
    "                # Compute the mean\n",
    "                field_mean = global_mean_pool(field, batch).reshape(-1, mul, 1)  # [batch, mul, 1]]\n",
    "                # Subtract the mean\n",
    "                field = field - field_mean[batch]\n",
    "\n",
    "            # Then compute the rescaling factor (norm of each feature vector)\n",
    "            # Rescaling of the norms themselves based on the option \"normalization\"\n",
    "            if self.normalization == 'norm':\n",
    "                field_norm = field.pow(2).sum(-1)  # [batch * sample, mul]\n",
    "            elif self.normalization == 'component':\n",
    "                field_norm = field.pow(2).mean(-1)  # [batch * sample, mul]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid normalization option {}\".format(self.normalization))\n",
    "            # Reduction method\n",
    "            if self.reduce == 'mean':\n",
    "                field_norm = global_mean_pool(field_norm, batch)  # [batch, mul]\n",
    "            elif self.reduce == 'max':\n",
    "                field_norm = global_max_pool(field_norm, batch)  # [batch, mul]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid reduce option {}\".format(self.reduce))\n",
    "\n",
    "            # Then apply the rescaling (divide by the sqrt of the squared_norm, i.e., divide by the norm\n",
    "            field_norm = (field_norm + self.eps).pow(-0.5)  # [batch, mul]\n",
    "\n",
    "            if self.affine:\n",
    "                weight = self.weight[None, iw: iw + mul]  # [batch, mul]\n",
    "                iw += mul\n",
    "                field_norm = field_norm * weight  # [batch, mul]\n",
    "\n",
    "            field = field * field_norm[batch].reshape(-1, mul, 1)  # [batch * sample, mul, repr]\n",
    "\n",
    "            if self.affine and d == 1:  # scalars\n",
    "                bias = self.bias[ib: ib + mul]  # [batch, mul]\n",
    "                ib += mul\n",
    "                field += bias.reshape(mul, 1)  # [batch * sample, mul, repr]\n",
    "\n",
    "            # Save the result, to be stacked later with the rest\n",
    "            fields.append(field.reshape(-1, mul * d))  # [batch * sample, mul * repr]\n",
    "\n",
    "        if ix != dim:\n",
    "            fmt = \"`ix` should have reached input.size(-1) ({}), but it ended at {}\"\n",
    "            msg = fmt.format(dim, ix)\n",
    "            raise AssertionError(msg)\n",
    "\n",
    "        output = torch.cat(fields, dim=-1)  # [batch * sample, stacked features]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6cd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from e3nn.o3 import Irreps, Linear, spherical_harmonics, FullyConnectedTensorProduct\n",
    "from e3nn.nn import Gate\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class O3TensorProduct(nn.Module):\n",
    "    \"\"\" A bilinear layer, computing CG tensorproduct and normalising them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in1 : o3.Irreps\n",
    "        Input irreps.\n",
    "    irreps_out : o3.Irreps\n",
    "        Output irreps.\n",
    "    irreps_in2 : o3.Irreps\n",
    "        Second input irreps.\n",
    "    tp_rescale : bool\n",
    "        If true, rescales the tensor product.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, irreps_in1, irreps_out, irreps_in2=None, tp_rescale=True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.irreps_in1 = irreps_in1\n",
    "        self.irreps_out = irreps_out\n",
    "        # Init irreps_in2\n",
    "        if irreps_in2 == None:\n",
    "            self.irreps_in2_provided = False\n",
    "            self.irreps_in2 = Irreps(\"1x0e\")\n",
    "        else:\n",
    "            self.irreps_in2_provided = True\n",
    "            self.irreps_in2 = irreps_in2\n",
    "        self.tp_rescale = tp_rescale\n",
    "\n",
    "        # Build the layers\n",
    "        self.tp = FullyConnectedTensorProduct(\n",
    "            irreps_in1=self.irreps_in1,\n",
    "            irreps_in2=self.irreps_in2,\n",
    "            irreps_out=self.irreps_out, shared_weights=True, normalization='component')\n",
    "\n",
    "        # For each zeroth order output irrep we need a bias\n",
    "        # So first determine the order for each output tensor and their dims\n",
    "        self.irreps_out_orders = [int(irrep_str[-2]) for irrep_str in str(irreps_out).split('+')]\n",
    "        self.irreps_out_dims = [int(irrep_str.split('x')[0]) for irrep_str in str(irreps_out).split('+')]\n",
    "        self.irreps_out_slices = irreps_out.slices()\n",
    "        # Store tuples of slices and corresponding biases in a list\n",
    "        self.biases = []\n",
    "        self.biases_slices = []\n",
    "        self.biases_slice_idx = []\n",
    "        for slice_idx in range(len(self.irreps_out_orders)):\n",
    "            if self.irreps_out_orders[slice_idx] == 0:\n",
    "                out_slice = irreps_out.slices()[slice_idx]\n",
    "                out_bias = torch.zeros(self.irreps_out_dims[slice_idx], dtype=self.tp.weight.dtype)\n",
    "                self.biases += [out_bias]\n",
    "                self.biases_slices += [out_slice]\n",
    "                self.biases_slice_idx += [slice_idx]\n",
    "\n",
    "        # Initialize the correction factors\n",
    "        self.slices_sqrt_k = {}\n",
    "\n",
    "        # Initialize similar to the torch.nn.Linear\n",
    "        self.tensor_product_init()\n",
    "        # Adapt parameters so they can be applied using vector operations.\n",
    "        self.vectorise()\n",
    "\n",
    "    def tensor_product_init(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            # Determine fan_in for each slice, it could be that each output slice is updated via several instructions\n",
    "            slices_fan_in = {}  # fan_in per slice\n",
    "            for weight, instr in zip(self.tp.weight_views(), self.tp.instructions):\n",
    "                slice_idx = instr[2]\n",
    "                mul_1, mul_2, mul_out = weight.shape\n",
    "                fan_in = mul_1 * mul_2\n",
    "                slices_fan_in[slice_idx] = (slices_fan_in[slice_idx] +\n",
    "                                            fan_in if slice_idx in slices_fan_in.keys() else fan_in)\n",
    "            # Do the initialization of the weights in each instruction\n",
    "            for weight, instr in zip(self.tp.weight_views(), self.tp.instructions):\n",
    "                # The tensor product in e3nn already normalizes proportional to 1 / sqrt(fan_in), and the weights are by\n",
    "                # default initialized with unif(-1,1). However, we want to be consistent with torch.nn.Linear and\n",
    "                # initialize the weights with unif(-sqrt(k),sqrt(k)), with k = 1 / fan_in\n",
    "                slice_idx = instr[2]\n",
    "                if self.tp_rescale:\n",
    "                    sqrt_k = 1 / sqrt(slices_fan_in[slice_idx])\n",
    "                else:\n",
    "                    sqrt_k = 1.\n",
    "                weight.data.uniform_(-sqrt_k, sqrt_k)\n",
    "                self.slices_sqrt_k[slice_idx] = (self.irreps_out_slices[slice_idx], sqrt_k)\n",
    "\n",
    "            # Initialize the biases\n",
    "            for (out_slice_idx, out_slice, out_bias) in zip(self.biases_slice_idx, self.biases_slices, self.biases):\n",
    "                sqrt_k = 1 / sqrt(slices_fan_in[out_slice_idx])\n",
    "                out_bias.uniform_(-sqrt_k, sqrt_k)\n",
    "\n",
    "    def vectorise(self):\n",
    "        \"\"\" Adapts the bias parameter and the sqrt_k corrections so they can be applied using vectorised operations \"\"\"\n",
    "\n",
    "        # Vectorise the bias parameters\n",
    "        if len(self.biases) > 0:\n",
    "            with torch.no_grad():\n",
    "                self.biases = torch.cat(self.biases, dim=0)\n",
    "            self.biases = nn.Parameter(self.biases)\n",
    "\n",
    "            # Compute broadcast indices.\n",
    "            bias_idx = torch.LongTensor()\n",
    "            for slice_idx in range(len(self.irreps_out_orders)):\n",
    "                if self.irreps_out_orders[slice_idx] == 0:\n",
    "                    out_slice = self.irreps_out.slices()[slice_idx]\n",
    "                    bias_idx = torch.cat((bias_idx, torch.arange(out_slice.start, out_slice.stop).long()), dim=0)\n",
    "\n",
    "            self.register_buffer(\"bias_idx\", bias_idx, persistent=False)\n",
    "        else:\n",
    "            self.biases = None\n",
    "\n",
    "        # Now onto the sqrt_k correction\n",
    "        sqrt_k_correction = torch.zeros(self.irreps_out.dim)\n",
    "        for instr in self.tp.instructions:\n",
    "            slice_idx = instr[2]\n",
    "            slice, sqrt_k = self.slices_sqrt_k[slice_idx]\n",
    "            sqrt_k_correction[slice] = sqrt_k\n",
    "\n",
    "        # Make sure bias_idx and sqrt_k_correction are on same device as module\n",
    "        self.register_buffer(\"sqrt_k_correction\", sqrt_k_correction, persistent=False)\n",
    "\n",
    "    def forward_tp_rescale_bias(self, data_in1, data_in2=None) -> torch.Tensor:\n",
    "        if data_in2 == None:\n",
    "            data_in2 = torch.ones_like(data_in1[:, 0:1])\n",
    "\n",
    "        data_out = self.tp(data_in1, data_in2)\n",
    "\n",
    "        # Apply corrections\n",
    "        if self.tp_rescale:\n",
    "            data_out /= self.sqrt_k_correction\n",
    "\n",
    "        # Add the biases\n",
    "        if self.biases is not None:\n",
    "            data_out[:, self.bias_idx] += self.biases\n",
    "        return data_out\n",
    "\n",
    "    def forward(self, data_in1, data_in2=None) -> torch.Tensor:\n",
    "        # Apply the tensor product, the rescaling and the bias\n",
    "        data_out = self.forward_tp_rescale_bias(data_in1, data_in2)\n",
    "        return data_out\n",
    "\n",
    "\n",
    "class O3TensorProductSwishGate(O3TensorProduct):\n",
    "    def __init__(self, irreps_in1, irreps_out, irreps_in2=None) -> None:\n",
    "        # For the gate the output of the linear needs to have an extra number of scalar irreps equal to the amount of\n",
    "        # non scalar irreps:\n",
    "        # The first type is assumed to be scalar and passed through the activation\n",
    "        irreps_g_scalars = Irreps(str(irreps_out[0]))\n",
    "        # The remaining types are gated\n",
    "        irreps_g_gate = Irreps(\"{}x0e\".format(irreps_out.num_irreps - irreps_g_scalars.num_irreps))\n",
    "        irreps_g_gated = Irreps(str(irreps_out[1:]))\n",
    "        # So the gate needs the following irrep as input, this is the output irrep of the tensor product\n",
    "        irreps_g = (irreps_g_scalars + irreps_g_gate + irreps_g_gated).simplify()\n",
    "\n",
    "        # Build the layers\n",
    "        super(O3TensorProductSwishGate, self).__init__(irreps_in1, irreps_g, irreps_in2)\n",
    "        if irreps_g_gated.num_irreps > 0:\n",
    "            self.gate = Gate(irreps_g_scalars, [nn.SiLU()], irreps_g_gate, [torch.sigmoid], irreps_g_gated)\n",
    "        else:\n",
    "            self.gate = nn.SiLU()\n",
    "\n",
    "    def forward(self, data_in1, data_in2=None) -> torch.Tensor:\n",
    "        # Apply the tensor product, the rescaling and the bias\n",
    "        data_out = self.forward_tp_rescale_bias(data_in1, data_in2)\n",
    "        # Apply the gate\n",
    "        data_out = self.gate(data_out)\n",
    "        # Return result\n",
    "        return data_out\n",
    "\n",
    "\n",
    "class O3SwishGate(torch.nn.Module):\n",
    "    def __init__(self, irreps_g_scalars, irreps_g_gate, irreps_g_gated) -> None:\n",
    "        super().__init__()\n",
    "        if irreps_g_gated.num_irreps > 0:\n",
    "            self.gate = Gate(irreps_g_scalars, [nn.SiLU()], irreps_g_gate, [torch.sigmoid], irreps_g_gated)\n",
    "        else:\n",
    "            self.gate = nn.SiLU()\n",
    "\n",
    "    def forward(self, data_in) -> torch.Tensor:\n",
    "        data_out = self.gate(data_in)\n",
    "        return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9d6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, global_add_pool\n",
    "from e3nn.nn import BatchNorm\n",
    "import numpy as np\n",
    "from e3nn.o3 import Irreps\n",
    "\n",
    "class SEGNN(nn.Module):\n",
    "    \"\"\"Steerable E(3) equivariant message passing network\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_irreps,\n",
    "        hidden_irreps,\n",
    "        output_irreps,\n",
    "        edge_attr_irreps,\n",
    "        node_attr_irreps,\n",
    "        num_layers,\n",
    "        norm=None,\n",
    "        pool=\"avg\",\n",
    "        task=\"graph\",\n",
    "        additional_message_irreps=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.task = task\n",
    "        # Create network, embedding first\n",
    "        # self.embedding_layer_1 = O3TensorProductSwishGate(\n",
    "        #     input_irreps, hidden_irreps, node_attr_irreps\n",
    "        # )\n",
    "        # self.embedding_layer_2 = O3TensorProduct(\n",
    "        #     hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "        # )\n",
    "\n",
    "        self.embedding_layer = O3TensorProduct(\n",
    "            input_irreps, hidden_irreps, node_attr_irreps\n",
    "        )\n",
    "\n",
    "        # Message passing layers.\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(\n",
    "                SEGNNLayer(\n",
    "                    hidden_irreps,\n",
    "                    hidden_irreps,\n",
    "                    hidden_irreps,\n",
    "                    edge_attr_irreps,\n",
    "                    node_attr_irreps,\n",
    "                    norm=norm,\n",
    "                    additional_message_irreps=additional_message_irreps,\n",
    "                )\n",
    "            )\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # Prepare for output irreps, since the attrs will disappear after pooling\n",
    "        if task == \"graph\":\n",
    "            pooled_irreps = (\n",
    "                (output_irreps * hidden_irreps.num_irreps).simplify().sort().irreps\n",
    "            )\n",
    "            self.pre_pool1 = O3TensorProductSwishGate(\n",
    "                hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "            )\n",
    "            self.pre_pool2 = O3TensorProduct(\n",
    "                hidden_irreps, pooled_irreps, node_attr_irreps\n",
    "            )\n",
    "            self.post_pool1 = O3TensorProductSwishGate(pooled_irreps, pooled_irreps)\n",
    "            self.post_pool2 = O3TensorProduct(pooled_irreps, output_irreps)\n",
    "            self.init_pooler(pool)\n",
    "        elif task == \"node\":\n",
    "            self.pre_pool1 = O3TensorProductSwishGate(\n",
    "                hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "            )\n",
    "            self.pre_pool2 = O3TensorProduct(\n",
    "                hidden_irreps, output_irreps, node_attr_irreps\n",
    "            )\n",
    "\n",
    "    def init_pooler(self, pool):\n",
    "        \"\"\"Initialise pooling mechanism\"\"\"\n",
    "        if pool == \"avg\":\n",
    "            self.pooler = global_mean_pool\n",
    "        elif pool == \"sum\":\n",
    "            self.pooler = global_add_pool\n",
    "\n",
    "    def catch_isolated_nodes(self, graph):\n",
    "        \"\"\"Isolated nodes should also obtain attributes\"\"\"\n",
    "        if (\n",
    "            graph.contains_isolated_nodes()\n",
    "            and graph.edge_index.max().item() + 1 != graph.num_nodes\n",
    "        ):\n",
    "            nr_add_attr = graph.num_nodes - (graph.edge_index.max().item() + 1)\n",
    "            add_attr = graph.node_attr.new_tensor(\n",
    "                np.zeros((nr_add_attr, node_attr.shape[-1]))\n",
    "            )\n",
    "            graph.node_attr = torch.cat((graph.node_attr, add_attr), -2)\n",
    "        # Trivial irrep value should always be 1 (is automatically so for connected nodes, but isolated nodes are now 0)\n",
    "        graph.node_attr[:, 0] = 1.0\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \"\"\"SEGNN forward pass\"\"\"\n",
    "        x, pos, edge_index, edge_attr, node_attr, batch = (\n",
    "            graph.x,\n",
    "            graph.pos,\n",
    "            graph.edge_index,\n",
    "            graph.edge_attr,\n",
    "            graph.node_attr,\n",
    "            graph.batch,\n",
    "        )\n",
    "        try:\n",
    "            additional_message_features = graph.additional_message_features\n",
    "        except AttributeError:\n",
    "            additional_message_features = None\n",
    "\n",
    "        self.catch_isolated_nodes(graph)\n",
    "\n",
    "        # Embed\n",
    "        # x = self.embedding_layer_1(x, node_attr)\n",
    "        # x = self.embedding_layer_2(x, node_attr)\n",
    "        x = self.embedding_layer(x, node_attr)\n",
    "\n",
    "        # Pass messages\n",
    "        for layer in self.layers:\n",
    "            x = layer(\n",
    "                x, edge_index, edge_attr, node_attr, batch, additional_message_features\n",
    "            )\n",
    "\n",
    "        # Pre pool\n",
    "        x = self.pre_pool1(x, node_attr)\n",
    "        x = self.pre_pool2(x, node_attr)\n",
    "\n",
    "        if self.task == \"graph\":\n",
    "            # Pool over nodes\n",
    "            x = self.pooler(x, batch)\n",
    "\n",
    "            # Predict\n",
    "            x = self.post_pool1(x)\n",
    "            x = self.post_pool2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SEGNNLayer(MessagePassing):\n",
    "    \"\"\"E(3) equivariant message passing layer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_irreps,\n",
    "        hidden_irreps,\n",
    "        output_irreps,\n",
    "        edge_attr_irreps,\n",
    "        node_attr_irreps,\n",
    "        norm=None,\n",
    "        additional_message_irreps=None,\n",
    "    ):\n",
    "        super().__init__(node_dim=-2, aggr=\"add\")\n",
    "        self.hidden_irreps = hidden_irreps\n",
    "\n",
    "        message_input_irreps = (2 * input_irreps + additional_message_irreps).simplify()\n",
    "        update_input_irreps = (input_irreps + hidden_irreps).simplify()\n",
    "\n",
    "        self.message_layer_1 = O3TensorProductSwishGate(\n",
    "            message_input_irreps, hidden_irreps, edge_attr_irreps\n",
    "        )\n",
    "        self.message_layer_2 = O3TensorProductSwishGate(\n",
    "            hidden_irreps, hidden_irreps, edge_attr_irreps\n",
    "        )\n",
    "        self.update_layer_1 = O3TensorProductSwishGate(\n",
    "            update_input_irreps, hidden_irreps, node_attr_irreps\n",
    "        )\n",
    "        self.update_layer_2 = O3TensorProduct(\n",
    "            hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "        )\n",
    "\n",
    "        self.setup_normalisation(norm)\n",
    "\n",
    "    def setup_normalisation(self, norm):\n",
    "        \"\"\"Set up normalisation, either batch or instance norm\"\"\"\n",
    "        self.norm = norm\n",
    "        self.feature_norm = None\n",
    "        self.message_norm = None\n",
    "\n",
    "        if norm == \"batch\":\n",
    "            self.feature_norm = BatchNorm(self.hidden_irreps)\n",
    "            self.message_norm = BatchNorm(self.hidden_irreps)\n",
    "        elif norm == \"instance\":\n",
    "            self.feature_norm = InstanceNorm(self.hidden_irreps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        edge_index,\n",
    "        edge_attr,\n",
    "        node_attr,\n",
    "        batch,\n",
    "        additional_message_features=None,\n",
    "    ):\n",
    "        \"\"\"Propagate messages along edges\"\"\"\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=x,\n",
    "            node_attr=node_attr,\n",
    "            edge_attr=edge_attr,\n",
    "            additional_message_features=additional_message_features,\n",
    "        )\n",
    "        # Normalise features\n",
    "        if self.feature_norm:\n",
    "            if self.norm == \"batch\":\n",
    "                x = self.feature_norm(x)\n",
    "            elif self.norm == \"instance\":\n",
    "                x = self.feature_norm(x, batch)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr, additional_message_features):\n",
    "        \"\"\"Create messages\"\"\"\n",
    "        if additional_message_features is None:\n",
    "            input = torch.cat((x_i, x_j), dim=-1)\n",
    "        else:\n",
    "            input = torch.cat((x_i, x_j, additional_message_features), dim=-1)\n",
    "\n",
    "        message = self.message_layer_1(input, edge_attr)\n",
    "        message = self.message_layer_2(message, edge_attr)\n",
    "\n",
    "        if self.message_norm:\n",
    "            message = self.message_norm(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x, node_attr):\n",
    "        \"\"\"Update note features\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_layer_1(input, node_attr)\n",
    "        update = self.update_layer_2(update, node_attr)\n",
    "        x += update  # Residual connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class O3Transform:\n",
    "    def __init__(self, lmax_attr):\n",
    "        self.attr_irreps = Irreps.spherical_harmonics(lmax_attr)\n",
    "\n",
    "    def __call__(self, graph):\n",
    "        pos = graph.pos\n",
    "        vel = graph.vel\n",
    "        charges = graph.charges\n",
    "\n",
    "#         prod_charges = charges[graph.edge_index[0]] * charges[graph.edge_index[1]]\n",
    "        rel_pos = pos[graph.edge_index[0]] - pos[graph.edge_index[1]]\n",
    "#         edge_dist = torch.sqrt(rel_pos.pow(2).sum(1, keepdims=True))\n",
    "\n",
    "        graph.edge_attr = spherical_harmonics(self.attr_irreps, rel_pos, normalize=True, normalization='integral')\n",
    "#         vel_embedding = spherical_harmonics(self.attr_irreps, vel, normalize=True, normalization='integral')\n",
    "        graph.node_attr = scatter(graph.edge_attr, graph.edge_index[1], dim=0, reduce=\"mean\") + vel_embedding\n",
    "\n",
    "#         vel_abs = torch.sqrt(vel.pow(2).sum(1, keepdims=True))\n",
    "#         mean_pos = pos.mean(1, keepdims=True)\n",
    "\n",
    "#         graph.x = torch.cat((pos - mean_pos, vel, vel_abs), 1)\n",
    "#         graph.additional_message_features = torch.cat((edge_dist, prod_charges), dim=-1)\n",
    "        \n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "584bf4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"graph\"\n",
    "# if args.feature_type == \"one_hot\":\n",
    "#     input_irreps = Irreps(\"5x0e\")\n",
    "# elif args.feature_type == \"cormorant\":\n",
    "#     input_irreps = Irreps(\"15x0e\")\n",
    "# elif args.feature_type == \"gilmer\":\n",
    "input_irreps = Irreps(\"11x0e\")\n",
    "lmax_h=2\n",
    "hidden_features=128\n",
    "hidden_irreps = BalancedIrreps(lmax_h,hidden_features, True)\n",
    "output_irreps = Irreps(\"1x0e\")\n",
    "lmax_attr=3\n",
    "edge_attr_irreps = Irreps.spherical_harmonics(lmax_attr)\n",
    "node_attr_irreps = Irreps.spherical_harmonics(lmax_attr)\n",
    "additional_message_irreps = Irreps(\"1x0e\")\n",
    "layers=7\n",
    "norm='instance'\n",
    "pool='avg'\n",
    "\n",
    "\n",
    "model = SEGNN(input_irreps,\n",
    "              hidden_irreps,\n",
    "              output_irreps,\n",
    "              edge_attr_irreps,\n",
    "              node_attr_irreps,\n",
    "              num_layers=7,\n",
    "              norm=norm,\n",
    "              pool=pool,\n",
    "              task=task,\n",
    "              additional_message_irreps=additional_message_irreps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b01a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
