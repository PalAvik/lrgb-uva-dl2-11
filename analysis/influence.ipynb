{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(r'inf_scores_GT.pkl', 'rb') as f:\n",
    "    all_res = pickle.load(f)\n",
    "    print(f\"{len(all_res)} graphs loaded\")\n",
    "\n",
    "x = all_res[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalisation code\n",
    "\n",
    "inf = x['influence_score'].copy()\n",
    "\n",
    "def row_normalise(inf):\n",
    "\n",
    "    row_totals = inf.sum(axis=1)\n",
    "    norm = (inf.T/row_totals).T\n",
    "\n",
    "    return norm\n",
    "\n",
    "assert np.allclose(row_normalise(inf).sum(axis=1), 1.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inf = row_normalise(inf)\n",
    "df = pd.DataFrame(inf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.index.name = 'source' # TODO is this right?\n",
    "\n",
    "melted = df.melt(ignore_index = False)\n",
    "melted = melted.reset_index() # Move source index to be a column, gives unique index\n",
    "melted = melted.rename(columns={'variable': 'target',\n",
    "                                'value': 'influence_score',\n",
    "                                'index': 'source'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source_coords = pd.DataFrame(x['xpos'])\n",
    "target_coords = source_coords.copy()\n",
    "\n",
    "source_coords.index.name = 'source'\n",
    "source_coords = source_coords.reset_index()\n",
    "\n",
    "target_coords.index.name = 'target'\n",
    "target_coords = target_coords.reset_index()\n",
    "\n",
    "\n",
    "target_cords = target_coords.rename(columns={0: 'target_x', 1: 'target_y'})\n",
    "source_coords = source_coords.rename(columns={0: 'source_x', 1: 'source_y'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(melted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "melted = melted.merge(source_coords, on='source', how='left')\n",
    "melted = melted.merge(target_cords, on='target', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(melted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "melted['distance_sq'] = (melted['source_x'] - melted['target_x'])**2 + (melted['source_y'] -\n",
    "                                                                        melted['target_y'] )**2\n",
    "melted['distance'] = np.sqrt(melted['distance_sq'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(melted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "melted.plot.scatter('distance', 'influence_score', logy=False, alpha=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph Based Distance Measure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edges = x['edges'].copy().astype(int)\n",
    "\n",
    "coords = x['xpos'].copy()\n",
    "\n",
    "edges = torch.Tensor(edges)\n",
    "coords = torch.Tensor(coords)\n",
    "\n",
    "data = tg.data.Data(edge_index=edges,\n",
    "                    x=coords)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = tg.utils.convert.to_networkx(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shortest_paths = nx.algorithms.shortest_paths.dense.floyd_warshall_numpy(g, weight=None)\n",
    "shortest_paths = pd.DataFrame(shortest_paths)\n",
    "\n",
    "shortest_paths_map = shortest_paths.melt(ignore_index=False)\n",
    "shortest_paths_map = shortest_paths_map.reset_index()\n",
    "shortest_paths_map = shortest_paths_map.rename(columns={'index': 'source',\n",
    "                                                        'variable': 'target',\n",
    "                                                        'value': 'graph_distance'}\n",
    "                                               )\n",
    "\n",
    "shortest_paths_map['graph_distance'] = shortest_paths_map['graph_distance'].astype('int')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "melted = melted.merge(shortest_paths_map, on=['source', 'target'])\n",
    "melted.plot.scatter('graph_distance', 'influence_score', logy=False, alpha=0.2,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "per_distance_per_source = melted.groupby(['graph_distance', 'source'])['influence_score'].sum()\n",
    "per_distance_per_source.groupby('graph_distance').mean().plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "per_distance_per_source.groupby('graph_distance').mean().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Put all of the above into a function, and run it on multiple graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_positions_to_df(positions_array, label):\n",
    "    assert label in {'source', 'target'}\n",
    "\n",
    "    coords = pd.DataFrame(positions_array)\n",
    "\n",
    "    coords.index.name = label\n",
    "    coords = coords.reset_index()\n",
    "    coords = coords.rename(columns={0: f'{label}_x',\n",
    "                                    1: f'{label}_y'}\n",
    "                           )\n",
    "    return coords\n",
    "\n",
    "\n",
    "def convert_arrays_to_df(influence_matrix, positions):\n",
    "    df = pd.DataFrame(influence_matrix)\n",
    "\n",
    "    df.index.name = 'source'  # TODO is this right?\n",
    "\n",
    "    melted = df.melt(ignore_index=False)\n",
    "    melted = melted.reset_index()  # Move source index to be a column, gives unique index\n",
    "    melted = melted.rename(columns={'variable': 'target',\n",
    "                                    'value': 'influence_score',\n",
    "                                    'index': 'source'})\n",
    "\n",
    "    source_coords = convert_positions_to_df(positions, label='source')\n",
    "    target_coords = convert_positions_to_df(positions, label='target')\n",
    "\n",
    "    melted = melted.merge(source_coords, on='source', how='left')\n",
    "    melted = melted.merge(target_coords, on='target', how='left')\n",
    "\n",
    "    return melted\n",
    "\n",
    "def calculate_distance(influence_df):\n",
    "    influence_df['distance_sq'] = (influence_df['source_x'] - influence_df['target_x'])**2 + (influence_df['source_y'] -\n",
    "                                                                        influence_df['target_y'] )**2\n",
    "    influence_df['distance'] = np.sqrt(influence_df['distance_sq'])\n",
    "\n",
    "    return influence_df\n",
    "\n",
    "\n",
    "def get_graph(edge_array, position_array):\n",
    "\n",
    "    edges = edge_array.astype(int)\n",
    "\n",
    "    edges = torch.Tensor(edges)\n",
    "    position_array = torch.Tensor(position_array)\n",
    "\n",
    "    data = tg.data.Data(edge_index=edges,\n",
    "                        x=position_array)\n",
    "\n",
    "    graph = tg.utils.convert.to_networkx(data)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def add_graph_distances_to_df(influence_df, graph):\n",
    "    shortest_paths = nx.algorithms.shortest_paths.dense.floyd_warshall_numpy(graph, weight=None)\n",
    "    shortest_paths = pd.DataFrame(shortest_paths)\n",
    "\n",
    "    shortest_paths_map = shortest_paths.melt(ignore_index=False)\n",
    "    shortest_paths_map = shortest_paths_map.reset_index()\n",
    "    shortest_paths_map = shortest_paths_map.rename(columns={'index': 'source',\n",
    "                                                            'variable': 'target',\n",
    "                                                            'value': 'graph_distance'}\n",
    "                                                   )\n",
    "\n",
    "    shortest_paths_map['graph_distance'] = shortest_paths_map['graph_distance'].astype('int')\n",
    "\n",
    "    influence_df = influence_df.merge(shortest_paths_map, on=['source', 'target'])\n",
    "\n",
    "    return influence_df\n",
    "\n",
    "def raw_data_to_df(influence_matrix, position_array, edge_array, normalise):\n",
    "\n",
    "    if normalise:\n",
    "        print('Normalising influence matrix')\n",
    "        influence_matrix = row_normalise(influence_matrix)\n",
    "\n",
    "    influence_df = convert_arrays_to_df(influence_matrix, position_array)\n",
    "    influence_df = calculate_distance(influence_df)\n",
    "    graph = get_graph(edge_array, position_array)\n",
    "\n",
    "    influence_df = add_graph_distances_to_df(influence_df, graph)\n",
    "\n",
    "    return  influence_df\n",
    "\n",
    "\n",
    "def process_all_graphs(pickle_file, normalise=False):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        all_graphs = pickle.load(f)\n",
    "        print(f\"{len(all_graphs)} graphs loaded\")\n",
    "\n",
    "    dfs = []\n",
    "    for i,graph in enumerate(all_graphs):\n",
    "        influence_df = raw_data_to_df(graph['influence_score'],\n",
    "                                      graph['xpos'],\n",
    "                                      graph['edges'],\n",
    "                                      normalise=normalise)\n",
    "        influence_df['graph_id'] = i\n",
    "        dfs.append(influence_df)\n",
    "\n",
    "    final_df = pd.concat(dfs)\n",
    "    final_df = final_df.sort_values(by='influence_score')\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "influence_df_gcn = process_all_graphs('inf_scores_gcn.pkl', normalise=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "influence_df_transformer = process_all_graphs('inf_scores_GT.pkl', normalise=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "influence_df_egnn = process_all_graphs('inf_scores_egnn.pkl', normalise=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# influence_df_gcn.plot.scatter('distance',\n",
    "#                                   'influence_score',\n",
    "#                                   logy=True,\n",
    "#                                   ax=ax,\n",
    "#                                   color='b')\n",
    "#\n",
    "# influence_df_transformer.plot.scatter('distance',\n",
    "#                                 'influence_score',\n",
    "#                                 logy=True,\n",
    "#                                 ax=ax,\n",
    "#                                 color='orange')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# influence_df_gcn.plot.scatter('graph_distance',\n",
    "#                                   'influence_score',\n",
    "#                                   logy=True,\n",
    "#                                   ax=ax,\n",
    "#                                   color='b')\n",
    "#\n",
    "#\n",
    "# # influence_df_egnn.plot.scatter('graph_distance',\n",
    "# #                                 'influence_score',\n",
    "# #                                 logy=True,\n",
    "# #                                 ax=ax,\n",
    "# #                                 color='orange')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "per_distance_per_source_trans = influence_df_transformer.groupby(['graph_distance', 'source'])['influence_score'].sum()\n",
    "per_distance_per_source_trans.groupby('graph_distance').mean().plot(ax = ax, label='transformer')\n",
    "\n",
    "per_distance_per_source_gcn = influence_df_gcn.groupby(['graph_distance', 'source'])['influence_score'].sum()\n",
    "per_distance_per_source_gcn.groupby('graph_distance').mean().plot(ax=ax, label='gcn')\n",
    "\n",
    "per_distance_per_source_egnn = influence_df_egnn.groupby(['graph_distance', 'source'])['influence_score'].sum()\n",
    "per_distance_per_source_egnn.groupby('graph_distance').mean().plot(ax=ax, label='egnn')\n",
    "\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
