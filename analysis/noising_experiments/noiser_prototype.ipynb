{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as tg\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from graphgps.loader.dataset.voc_superpixels import VOCSuperpixels\n",
    "from functools import cached_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Load up the dataset\n",
    "\n",
    "dataset = VOCSuperpixels(root='../../../datasets/VOCSuperpixels',\n",
    "                         slic_compactness=30,\n",
    "                         name='edge_wt_only_coord',\n",
    "                         split='test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data = dataset[0].clone()\n",
    "graph = tg.utils.convert.to_networkx(data)\n",
    "\n",
    "\n",
    "# Only need to do this once, cache for later\n",
    "all_shortest_paths = nx.algorithms.shortest_paths.dense.floyd_warshall_numpy(graph).astype(int)\n",
    "\n",
    "# Identify a target node\n",
    "target_node_idx = 0\n",
    "\n",
    "# get the shortest paths to target node\n",
    "shortest_paths_to_target = all_shortest_paths[:, target_node_idx] # [i, j] is the shortest path from i to j"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "shortest_paths_df = pd.DataFrame(shortest_paths_to_target)\n",
    "shortest_paths_df = shortest_paths_df.reset_index().rename(columns = {'index': 'node_id',\n",
    "                                                         0: 'path_length'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Obtain the buckets corresponding to each path length. A map path_length -> node_ids with that path length\n",
    "path_length_buckets = shortest_paths_df.groupby('path_length')['node_id'].groups"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: [0], 1: [2, 25, 29, 41], 2: [1, 3, 19, 24, 28, 34, 45, 47, 53, 61, 65, 84], 3: [4, 16, 37, 42, 57, 66, 67, 80, 81, 96, 97], 4: [5, 6, 22, 30, 48, 59, 68, 76, 77, 85, 98, 106, 119, 120, 127], 5: [7, 8, 20, 35, 38, 54, 58, 75, 82, 99, 100, 101, 115, 117, 134, 137, 143, 152, 162, 173], 6: [9, 10, 23, 31, 43, 49, 72, 78, 93, 95, 111, 116, 121, 122, 138, 140, 153, 157, 163, 175, 191, 192, 200, 210], 7: [11, 18, 21, 32, 44, 50, 56, 69, 79, 86, 102, 113, 132, 133, 144, 154, 158, 169, 170, 179, 183, 201, 213, 216, 232, 233, 234, 252], 8: [12, 17, 26, 39, 51, 55, 62, 70, 71, 87, 107, 112, 118, 123, 135, 145, 151, 166, 177, 187, 190, 202, 208, 230, 245, 256, 263, 268, 292], 9: [13, 14, 15, 27, 33, 40, 46, 60, 73, 88, 89, 94, 108, 129, 131, 139, 141, 156, 167, 176, 188, 189, 204, 207, 217, 220, 223, 238, 253, 269, 272, 276, 283, 293, 312, 321, 336], 10: [36, 52, 63, 64, 74, 83, 90, 103, 104, 114, 130, 146, 149, 159, 168, 171, 185, 186, 194, 205, 212, 227, 229, 240, 246, 255, 260, 277, 284, 291, 301, 305, 308, 319, 329, 352, 353, 360, 371], 11: [91, 92, 105, 109, 110, 124, 125, 136, 150, 155, 172, 184, 196, 203, 209, 218, 219, 225, 228, 244, 262, 265, 266, 287, 296, 302, 314, 317, 324, 326, 338, 348, 366, 368, 379, 381, 382, 395], 12: [126, 128, 142, 147, 148, 160, 164, 174, 180, 193, 224, 226, 241, 242, 247, 250, 251, 254, 261, 273, 285, 309, 310, 322, 325, 328, 330, 341, 369, 383, 384, 397, 399, 404, 415, 416, 434], 13: [161, 165, 178, 181, 182, 197, 198, 206, 222, 231, 239, 243, 249, 264, 267, 278, 280, 281, 288, 303, 316, 331, 337, 339, 354, 358, 359, 376, 390, 405, 418, 419, 420, 436, 441, 456, 462, 463], 14: [195, 199, 211, 214, 215, 221, 248, 257, 270, 274, 286, 294, 297, 298, 300, 306, 320, 342, 346, 350, 357, 364, 372, 385, 387, 391, 406, 421, 433, 435, 443, 457, 464, 466], 15: [235, 236, 237, 258, 259, 271, 279, 289, 295, 313, 315, 318, 332, 340, 351, 370, 374, 377, 388, 389, 394, 400, 407, 413, 425, 437, 452, 453], 16: [275, 282, 290, 299, 304, 307, 311, 327, 333, 334, 335, 344, 345, 362, 365, 378, 392, 396, 398, 401, 417, 422, 447, 449, 454, 468], 17: [323, 343, 347, 349, 355, 356, 361, 363, 373, 402, 410, 414, 423, 426, 427, 430, 444, 445, 458, 465], 18: [367, 375, 380, 386, 408, 411, 424, 432, 438, 439, 442, 446, 450, 459, 460, 467], 19: [393, 403, 409, 412, 429, 448, 451, 461, 469], 20: [428, 431, 440, 455]}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_length_buckets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0,  1,  1, ..., 18, 15, 19],\n       [ 2,  0,  1, ..., 19, 16, 20],\n       [ 1,  1,  0, ..., 19, 16, 19],\n       ...,\n       [18, 18, 18, ...,  0,  4,  1],\n       [16, 16, 16, ...,  4,  0,  5],\n       [19, 19, 19, ...,  1,  5,  0]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_shortest_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "### First we need to decide what mask we are going to use - here are three options\n",
    "\n",
    "# Just fudge based on the standard deviation\n",
    "standard_deviation_of_input = data.x.std(dim=0)\n",
    "\n",
    "# Replace with the mean input values from this graph\n",
    "mean_of_input = data.x.mean(dim=0)\n",
    "\n",
    "# Replace with the mean inputs from the entire graph\n",
    "mean_of_means = []\n",
    "for d in dataset:\n",
    "    graph_mean = d.x.mean(dim=0)\n",
    "    mean_of_means.append(graph_mean)\n",
    "mean_of_means = torch.row_stack(mean_of_means)\n",
    "mean_of_means = mean_of_means.mean(0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Now fix some path_length and generate a mask for each path length that replaces those node values with a fudged value.\n",
    "\n",
    "path_length = 5\n",
    "\n",
    "new_data = data.clone()\n",
    "for index in path_length_buckets[path_length]:\n",
    "    new_data.x[index, :] = mean_of_means # can swap this bit out based on what we want to do"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
